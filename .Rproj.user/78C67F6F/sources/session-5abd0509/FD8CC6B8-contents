
#1
R1=C1=c(1,1)#R1
R4=C2=c(5,7)#R4
R2=c(1.5,2)
R3=c(3,4)
R5=c(3.5,5)
R6=c(4.5,5)
R7=c(3.5,4.5)
df<-data.frame(C1,C2,R2,R3,R5,R6,R7)
df
dist(t(df))
#      C1        C2        R2        R3        R5        R6
# C2 7.2111026                                                  
# R2 1.1180340 6.1032778                                        
# R3 3.6055513 3.6055513 2.5000000                              
# R5 4.7169906 2.5000000 3.6055513 1.1180340                    
# R6 5.3150729 2.0615528 4.2426407 1.8027756 1.0000000          
# R7 4.3011626 2.9154759 3.2015621 0.7071068 0.5000000 1.1180340

#cluster1={R1,R2,R3} #R3 asignado aleatoriamente
#cluster2={R4,R5,R6,R7}
#recalculamos centroides
C1<-apply(data.frame(R1,R2,R3),1,mean)
C2<-apply(data.frame(R4,R5,R6,R7),1,mean)


df<-data.frame(C1,C2,R1,R2,R3,R4,R5,R6,R7)
df
dist(t(df))
#       C1        C2        R1        R2        R3        R4       R5       R6
# C2 5.3764533                                                            
# R1 0.0000000 5.3764533                                                  
# R2 7.2111026 1.8456029 7.2111026                                        
# R3 3.6055513 1.7765838 3.6055513 3.6055513                              
# R4 7.2111026 1.8456029 7.2111026 0.0000000 3.6055513                    
# R5 4.7169906 0.7288690 4.7169906 2.5000000 1.1180340 2.5000000          
# R6 5.3150729 0.5303301 5.3150729 2.0615528 1.8027756 2.0615528 1.0000000
# R7 4.3011626 1.0752907 4.3011626 2.9154759 0.7071068 2.9154759 0.5000000 1.1180340

#cluster1={R1} 
#cluster2={R2,R3,R4,R5,R6,R7}

C1<-R1
C2<-apply(data.frame(R2,R3,R4,R5,R6,R7),1,mean)
df<-data.frame(C1,C2,R1,R2,R3,R4,R5,R6,R7)
df
dist(t(df))

C1
C2
#la situacion no cambia, esta es la configuracion de clusters finales

#2

#de la matriz de distancias se ve que los dos primeros puntos que se unen son los mascercanos 
#{p6 , p3} ,ahora usando complete linkage, ¿que otro punto/cluster se les uniria?
#distancia linkage {p6,p3} a p1 es max(0.23,0.22)=0.23
#distancia linkage {p6,p3} a p2 es max(0.25,0.15)=0.25
#distancia linkage {p6,p3} a p4 es max(0.22,0.15 )=0.22
#distancia linkage {p6,p3} a p5 es max(0.39,0.28)=0.39
#se les une p4 que es el que a menor distancia esta
#{p6 , p3,p4} ,ahora usando complete linkage, ¿que otro punto/cluster se les uniria?
#distancia linkage {p6,p3,p4} a p1 es max(0.23,0.22,0.37)=0.37
#distancia linkage {p6,p3,p4} a p2 es max(0.25,0.15,0.20)=0.25
#distancia linkage {p6,p3,p4} a p5 es max(0.39,0.28,0.29)=0.39
#se les une p2 que es el que a menor distancia esta
#{p6 , p3,p4,p2} ,ahora usando complete linkage, ¿que otro punto/cluster se les uniria?
#distancia linkage {p6,p3,p4,p2} a p1 es max(0.23,0.22,0.37,0.24)=0.37
#distancia linkage {p6,p3,p4,p2} a p5 es max(0.39,0.28,0.29,0.14)=0.39
#se les une p1 que es el que a menos distancia esta
#{p6 , p3,p4,p2,p1} y a continuacion p5
#{p6,p3}->{p6,p3,p4}->{p6,p3,p4,p2}->{p6,p3,p4,p2,p1}->{p6,p3,p4,p2,p5,p5}
#
library(recommenderlab)
#3

valores<-c(1,NA,1,1,1,NA,1,1,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,1,NA,NA,1,1)

m<-matrix(valores,ncol=5,nrow=5,byrow=TRUE)
m
mt<-matrix(c(NA,NA,1,NA,NA),ncol=5,nrow=1,byrow=TRUE)#usuario 2
mt
library(recommenderlab)
matriz_rec <- as(m,"realRatingMatrix")
matriz_test <- as(mt,"realRatingMatrix")
#nn=1
User_based_norm <- Recommender(matriz_rec,
                               "UBCF",
                               param=list( method="Euclidean",nn=1)) #"pearson"/"Cosine"
predicciones1 <- predict(User_based_norm, matriz_test, type="ratings")
predicciones1
getRatingMatrix(predicciones1)
#NO se recomendaria
#nn=2

User_based_norm <- Recommender(matriz_rec,
                               "UBCF",
                               param=list( method="Euclidean",nn=2)) #"pearson"/"Cosine"
predicciones1 <- predict(User_based_norm, matriz_test, type="ratings")
predicciones1
getRatingMatrix(predicciones1)
#SI se recomienda
#4
mt<-matrix(c(NA,NA,1,1,1),ncol=5,nrow=1,byrow=TRUE)#usuario 3
matriz_test <- as(mt,"realRatingMatrix")
User_based_norm <- Recommender(matriz_rec,
                               "IBCF",
                               param=list( method="Euclidean",k=1)) #"pearson"/"Cosine"
predicciones1 <- predict(User_based_norm, matriz_test, type="ratings")
predicciones1
getRatingMatrix(predicciones1)
#si 1 y 2, no el 
#5
user1<-c(1,4,5,1,3,6,5)
user2<-c(2,3,4,4,4,5,3)
valoraciones<-rbind(user1,user2)
valoraciones
valoracionesr<-as(valoraciones,"realRatingMatrix")

sim<-similarity(valoracionesr,which="users",method="Pearson")
sim
#6
library(xlsx)
library(tidyverse)
#library(help=xlsx)
setwd("C:\\Datuak\\KLASEAK\\GBDA\\2324\\datamining\\reto4\\examen\\2324\\recuperacion")
df<-read.csv("ratingv2.csv",sep=";")
dim(df)

head(df)
df<-df[,-4]
str(df)
R1<-length(unique(df$userId))
R2<-length(unique(df$movieId))
R3<-hist(df$rating);max(df$rating);min(df$rating)
dfp<-data.frame(pivot_wider(df,names_from = movieId,values_from = rating))
rownames(dfp)<-dfp[,1]
dfp<-dfp[,-1]
dfp<-as.matrix(dfp)
MR<-as(dfp,"realRatingMatrix")
dim(MR)
summary(colSums(MR))
hist(colSums(MR))
hist(rowSums(MR))
summary(colCounts(MR))
summary(rowCounts(MR))
hist(colCounts(MR))
hist(rowCounts(MR))
MRf1<-MR[,colCounts(MR)>80]#quitar los que tengan mas NA's que la media de NA's por columna
MRf2<-f1[rowCounts(MRf1)>150,]#quitar los que tengan mas NA's que la media de NA's por fila
dim(MRf2)


e<- evaluationScheme(data = MRf2, method = "split", train = 0.8,
                     given = 1, goodRating = 4)

#popular
popular<-Recommender(getData(e, "train"), "Popular")
prediccionesp<-predict(popular, getData(e, "known"), type="topNList")
as(prediccionesp, "list")
pred_pop<-calcPredictionAccuracy(prediccionesp, getData(e, "unknown"),given = 1, goodRating = 4)


#random
random<-Recommender(getData(e, "train"), "Random")
prediccionesr<-predict(random, getData(e, "known"), type="topNList")
as(prediccionesr, "list")
pred_random<-calcPredictionAccuracy(prediccionesr, getData(e, "unknown"),given = 1, goodRating = 4)



#SVD
SVD<-Recommender(getData(e, "train"), "SVD")
prediccionesvd<-predict(SVD, getData(e, "known"), type="topNList")
as(prediccionesvd, "list")
pred_svd<-calcPredictionAccuracy(prediccionesvd, getData(e, "unknown"),given = 1, goodRating = 4)


rbind(pred_pop,pred_random,pred_svd)
#el mejor es el popular
